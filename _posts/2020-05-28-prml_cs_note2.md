---
layout:     post
title:      "PRML通俗串烧02（二）"
subtitle:   "第二章 概率分布"
date:       2020-05-28 00:15:18
author:     "QIY"
header-img: "img/prml.jpg"
header-mask: 0.3 
catalog:    true
tags:
    - PRML
---


> PRML 的学习基本上是学十得一。稳扎稳打再来一次

* TOC
{:toc}

## 2.1 二元分布

### 2.1.1 伯努利分布

**其结果只有两个：合格或不合格；**购买彩票，开奖后，这张彩票的结果只有两个：中奖或没中奖；拨打女朋友电话：接通或没接通。。。以上这些事件都可被称为伯努利试验。

伯努利试验是单次随机试验，只有"成功（值为1）"或"失败（值为0）"这两种结果，是由瑞士科学家雅各布·伯努利(1654
- 1705)提出来的。

其概率分布称为伯**努利分布(Bernoulli
distribution)，也称为两点分布或者0-1分布**，是最简单的离散型概率分布。我们记成功概率为p(0≤p≤1)，则失败概率为q=1-p，则：

其概率质量函数为：

![](/img/in-post/200528_prml_glfb/8aef06735349ebf3e6bf671589673ac6.png)

其期望值为：

![](/img/in-post/200528_prml_glfb/8aded56187412428651f8e3408e2ec2f.png)

其方差为：

![](/img/in-post/200528_prml_glfb/931642ad3d7ef5e66342f598fd142561.png)

### 2.1.2 二项分布

假设某个试验是伯努利试验，其成功概率用p表示，那么失败的概率为q=1-p。进行n次这样的试验，**成功了x次，则失败次数为n-x，发生这种情况的概率可用下面公式来计算：**

![](/img/in-post/200528_prml_glfb/880055d4d2bf25d268adf3cfd4236a59.png)

**我们称上面的公式为二项分布**(Binomial distribution)的概率质量函数。其中

![](/img/in-post/200528_prml_glfb/cb092eb77601d718f8353c9b5b300fe3.png)

### 2.1.3 Beta分布

beta分布可以看作**一个概率的概率分布**，当你不知道一个东西的具体概率是多少时，**它可以给出了所有概率出现的可能性大小**。

举一个简单的例子，熟悉棒球运动的都知道有一个指标就是棒球击球率(batting
average)，就是用一个运动员击中的球数除以击球的总数，我们一般认为0.266是正常水平的击球率，而如果击球率高达0.3就被认为是非常优秀的。

现在有一个棒球运动员，我们希望能够预测他在这一赛季中的棒球击球率是多少。你可能就会直接计算棒球击球率，用击中的数除以击球数，但是如果这个棒球运动员只打了一次，而且还命中了，那么他就击球率就是100%了，这显然是不合理的，因为根据棒球的历史信息，我们知道这个击球率应该是0.215到0.36之间才对啊。

对于这个问题，我们可以用一个二项分布表示（一系列成功或失败），一个最好的方法来表示这些经验（在统计中称为先验信息）就是用beta分布，这表示在我们没有看到这个运动员打球之前，我们就有了一个大概的范围。beta分布的定义域是(0,1)这就跟概率的范围是一样的。

接下来我们将这些先验信息转换为beta分布的参数，我们知道一个击球率应该是平均0.27左右，而他的范围是0.21到0.35，那么根据这个信息，我们可以取α=81,β=219

![](/img/in-post/200528_prml_glfb/f72b7c58bd4eac42779bf387f12148e9.png)

之所以取这两个参数是因为：

beta分布的均值是

![](/img/in-post/200528_prml_glfb/cb3697be94321ea2b82ba3830afa4d79.png)

从图中可以看到这个分布主要落在了(0.2,0.35)间，这是从经验中得出的合理的范围。

在这个例子里，我们的x轴就表示各个击球率的取值，x对应的y值就是这个击球率所对应的概率。也就是说beta分布可以看作一个概率的概率分布。

那么有了先验信息后，现在我们考虑一个运动员只打一次球，那么他现在的数据就是”1中;1击”。这时候我们就可以更新我们的分布了，让这个曲线做一些移动去适应我们的新信息。beta分布在数学上就给我们提供了这一性质，他与二项分布是共轭先验的（[Conjugate_prior](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Conjugate_prior%23Example)）。所谓共轭先验就是先验分布是beta分布，而后验分布同样是beta分布。结果很简单：

![](/img/in-post/200528_prml_glfb/f7b7c070464749fa10a0438245cf4f55.png)

其中α0和β0是一开始的参数，在这里是81和219。所以在这一例子里，α增加了1(击中了一次)。β没有增加(没有漏球)。这就是我们的新的beta分布Beta(81+1,219)，我们跟原来的比较一下：

![](/img/in-post/200528_prml_glfb/6531ce60083a38d7308b52c4f9ead07f.png)

可以看到这个分布其实没多大变化，这是因为只打了1次球并不能说明什么问题。但是如果我们得到了更多的数据，假设一共打了300次，其中击中了100次，200次没击中，那么这一新分布就是：

![](/img/in-post/200528_prml_glfb/16696ddb9093d33a0047af322807509a.png)

![](/img/in-post/200528_prml_glfb/1a1950a47a3a570b9bf5f23bd87d8161.png)

注意到这个曲线变得更加尖，并且平移到了一个右边的位置，表示比平均水平要高。

一个有趣的事情是，根据这个新的beta分布，我们可以得出他的数学期望为：

![](/img/in-post/200528_prml_glfb/15950b54a00359d3fde6298084e10100.png)

，这一结果要比直接的估计要小

![](/img/in-post/200528_prml_glfb/44dc23b464a70f1071d9190320918de1.png)

。你可能已经意识到，我们事实上就是在这个运动员在击球之前可以理解为他已经成功了81次，失败了219次这样一个先验信息。

因此，对于一个我们不知道概率是什么，而又有一些合理的猜测时，beta分布能很好的作为一个表示概率的概率分布。

## 2.2 多项式变量

多项式分布是二项式分布的扩展，不同的是多项式分布中，每次实验有n种结果。

概率计算：

![](/img/in-post/200528_prml_glfb/f33d1210c3e668c348cb9811aa3861a5.png)

期望计算：

![](/img/in-post/200528_prml_glfb/74cd0059e415be1486c4eeecfd43ed24.png)

最简单的例子就是多次抛筛子，统计各个面被掷中的次数。

## 2.3 高斯分布（正态分布）

高斯分布的**概率密度函数**是：

![](/img/in-post/200528_prml_glfb/f7eb940b80a254682936cba49cf0aac1.png)

当

![](/img/in-post/200528_prml_glfb/1f12b5047950ec9633a0bccf208183cd.png)

 时，正态分布就成为**标准正态分布**

![](/img/in-post/200528_prml_glfb/49e291924f02114a90dca2db22df9adb.png)

；

### 2.3.1 条件高斯分布

多元高斯的一个重要性质：
如果两组变量是联合高斯分布，那以一组变量为条件，另一组变量同样是高斯分布。类似的，任何一个变量的**边缘分布**也是高斯分布。

首先来考虑条件概率的情形，本章的重要结论是得出**条件高斯分布**的

![](/img/in-post/200528_prml_glfb/d015026a52b2ee8e5d917f2d8b0ede46.png)

的均值和协方差的表达式为：

![](/img/in-post/200528_prml_glfb/3bdb3b47f4a3f7c110b93622e89faf2e.png)

### 2.3.2 边缘高斯分布

**边缘分布**（Marginal
Distribution）指在[概率论](https://baike.baidu.com/item/%E6%A6%82%E7%8E%87%E8%AE%BA)和[统计学](https://baike.baidu.com/item/%E7%BB%9F%E8%AE%A1%E5%AD%A6)的多维随机变量中，只包含其中部分变量的概率分布。

![](/img/in-post/200528_prml_glfb/25f4794fc06d07e21f63926ef0a7b4f6.png)

![](/img/in-post/200528_prml_glfb/6b30d39d5307458b17f6e4b9d8ffe5f6.png)

**对应绪论**

![](/img/in-post/200528_prml_glfb/4d76e95be907e1955bd3f18db1fd4e6f.png)

结论（均值和方差）：

![](/img/in-post/200528_prml_glfb/3938a57c3990ef87385d7a38f879261f.png)

### 2.3.3 高斯变量的贝叶斯定理

![](/img/in-post/200528_prml_glfb/042a08a871f7e81b070ebce0768606e7.png)

其中μ，A和b是控制均值的参数，Λ和L是精度矩阵。

### 2.3.5 顺序估计

对比“高斯分布的最大似然估计”当旧的错误时，把旧的估计沿着“错误信号”方向移动一个微小的量，随着N的增加，后续数据点的贡献逐步减小。

我们不能总是通过使用上述方法推出一个顺序算法，一个更加通用的算法是Robbins-Monro算法。

![](/img/in-post/200528_prml_glfb/205d4435f04f83e73143a3fbc7274d08.png)

### 2.3.6 高斯分布的贝叶斯推断

略

### 2.3.7 学生t分布
在[概率论](https://baike.baidu.com/item/%E6%A6%82%E7%8E%87%E8%AE%BA/829122)和[统计学](https://baike.baidu.com/item/%E7%BB%9F%E8%AE%A1%E5%AD%A6/1175)中，**t-分布**（*t*-distribution）用于根据小样本来**估计**呈[正态分布](https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892)且方差未知的总体的**均值**。如果总体方差已知（例如在样本数量足够多时），则应该用正态分布来估计总体均值。 [1] 

t分布曲线形态与n（确切地说与自由度df）大小有关。与标准正态分布曲线相比，自由度df越小，t分布曲线愈平坦，曲线中间愈低，曲线双侧尾部翘得愈高；自由度df愈大，t分布曲线愈接近正态分布曲线，当自由度df=∞时，t分布曲线为标准正态分布曲线。

由于在实际工作中，往往σ是未知的，常用s作为σ的估计值，为了与u变换区别，称为t变换，统计量t
值的分布称为t分布。 [1] 

**假设X服从标准正态分布N（0,1），Y服从**

![](/img/in-post/200528_prml_glfb/78de55f6c6a7f904d1aa7f7a09e2ff12.png)

**分布，那么**

![](/img/in-post/200528_prml_glfb/65a59679287f2391404b044305f66ce2.png)

**的分布称为自由度为n的t分布,记为**

![](/img/in-post/200528_prml_glfb/b77ed0c01aec38c9b00b1827b4653143.png)

**。**

分布密度函数

![](/img/in-post/200528_prml_glfb/97871b6990462d60a3760e341c3c00af.png)

 ，

其中，Gam(x)为伽马函数。

![](/img/in-post/200528_prml_glfb/208b1c4b71f30ff5300b391264698b5e.png)

![](/img/in-post/200528_prml_glfb/db606794309abcc25f6fcc3e5b1c8ff3.png)

### 2.3.9 高斯混合模型

#### 2.3.9.1 有时候单一高斯分布不能很好的描述分布

 

![](/img/in-post/200528_prml_glfb/7de81a5b49eb0262f692b1fd54c01cce.jpg)

image.png

-   上图左面用单一高斯分布去描述，显然没有右图用两个高斯分布去描述的效果好。

#### 2.3.9.2 引入混合高斯分布

这里插一句，为什么是“高斯混合模型”，而不是别的混合模型，因为从中心极限定理知，只要K足够大，模型足够复杂，样本量足够多，每一块小区域就可以用高斯分布描述。而且高斯函数具有良好的计算性能，所GMM被广泛地应用。

-   单一高斯分布公式

 

![](/img/in-post/200528_prml_glfb/b6319f46fdbf2bdfcf9c76bbb806b24a.jpg)

image.png

-   混合高斯分布

-   每个GMM由K个高斯分布组成，每个高斯分布称为一个组件（Component），这些组件线性加成在一起就组成了GMM的概率密度函数：

 

![](/img/in-post/200528_prml_glfb/92b0f9ba572724e6a3b7062147800a24.jpg)

image.png

 

![](/img/in-post/200528_prml_glfb/1c10257517ad61fa4b51ab1c1b36430a.jpg)

image.png

 

![](/img/in-post/200528_prml_glfb/240bc8159560a6fad692ab6675ed00cf.jpg)

image.png

-   如上图，我们用三个高斯分布去描述一个二维的数据。

 

![](/img/in-post/200528_prml_glfb/70d39514a5bd4a49569b4fdb24fa6035.jpg)

 

参考：<https://www.jianshu.com/p/928d48afcd9a>

## 2.4
指数族分布
略