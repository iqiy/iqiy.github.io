---
layout:     post
title:      "PRML通俗串烧03"
subtitle:   "第三章 线性回归模型
date:       2020-05-28 00:15:18
author:     "QIY"
header-img: "img/prml.jpg"
header-mask: 0.3 
catalog:    true
tags:
    - PRML
---


> 从基础做起

* TOC
{:toc}

# 线性回归模型

## 3.1 线性基函数模型
------------------

### 3.1.1 最大似然与最小平方

![](/img/in-post/200528_prml_xxhg/317806191ca4c09e81d6f6c8be2209af.png)

总结起来，最大似然估计的目的就是：**利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。**

       
原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“**模型已定，参数未知**”。通过若干次试验，观察其结果，**利用试验结果得到某个参数值能够使样本出现的概率为最大**，则称为极大似然估计。

最小平方（最小二乘法）：对于最小二乘估计来说，**最合理的参数估计量应该使得模型能最好地拟合样本数据**，也就是估计值与观测值之差的平方和最小。

![](/img/in-post/200528_prml_xxhg/2019cb78a4f8f9de29d601f298fc42be.png)

；

![](/img/in-post/200528_prml_xxhg/7c8614ea23215a32e35ff65b5034a71b.png)

；

## 3.3 贝叶斯线性回归
------------------

贝叶斯线性回归不仅可以解决极大似然估计中存在的过拟合的问题。

它对数据样本的利用率是100%，仅仅使用训练样本就可以有效而准确的确定模型的复杂度。

*在极大似然估计线性回归中我们把参数看成是一个未知的固定值，而贝叶斯学派则把看成是一个随机变量*。 

线性回归模型是一组输入变量的基函数的线性组合，在数学上其形式如下： 

![](/img/in-post/200528_prml_xxhg/160bf82c93ab5443996283d841d7d33d.png)

这里

![](/img/in-post/200528_prml_xxhg/798286e8494961452acf1bb18bb70cce.png)

就是前面提到的基函数，总共的基函数的数目为个，如果定义的话，那个上面的式子就可以简单的表示为： 

![](/img/in-post/200528_prml_xxhg/c62815721137c784d92a114023b8b155.png)

![](/img/in-post/200528_prml_xxhg/0db7406b3039c08b8390046c67c432ff.png)

![](/img/in-post/200528_prml_xxhg/8589a433dc635b05d3f197748f804491.png)

![](/img/in-post/200528_prml_xxhg/426bb93a0109437490e63d127a206bff.png)

![](/img/in-post/200528_prml_xxhg/6992bdfec905e652f9176ae21bafdca6.png)

几者过程对比：

**最小二乘法**：是估计值与观测值之差的平方和最小；

**最大似然**：只是对似然的处理，概率乘积转概率密度乘积，取对数转加，求导得估计值；

**贝叶斯线性回归**：

![](/img/in-post/200528_prml_xxhg/4cba3dfcce7eaf9840c00e0a670ccaa5.png)

<https://blog.csdn.net/qq_32742009/article/details/81485887>
