---
layout:     post
title:      "ML学习笔记（一）"
subtitle:   "SVM基础1"
date:       2020-06-03 20:33:18
author:     "QIY"
header-img: "img/ML.png"
header-mask: 0.3 
catalog:    true
tags:
    - Machine Learning
---


> Machine Learning 的学习需稳扎稳打

* TOC
{:toc}

# 1分类问题常用方法

![](/img/in-post/200603_ml_svm1/c2e2cd48b60f9a6fa765c532327aa5e2.png)

# 2支持向量机概述（Support Vector Machine, SVM）

（百度百科）支持向量机（Support Vector Machine,
SVM）是一类按监督学习（supervised learning）方式对数据进行二元分类（binary
classification）的广义线性分类器（generalized linear
classifier），其决策边界是对学习样本求解的最大边距超平面（maximum-margin
hyperplane） [1-3] 。

SVM使用铰链损失函数（hinge loss）计算经验风险（empirical
risk）并在求解系统中加入了正则化项以优化结构风险（structural
risk），是一个具有稀疏性和稳健性的分类器 [2] 。SVM可以通过核方法（kernel
method）进行非线性分类，是常见的核学习（kernel learning）方法之一 [4] 。

![](/img/in-post/200603_ml_svm1/90c791e134f793206b94de83b2ef9690.png)

hyperplane（要找的超平面）:有最大间隔的Large Margin 。

绿色的2个点，蓝色的3个点称谓Support Vectors 。

![https://qqadapt.qpic.cn/txdocpic/0/a38446480f9acfbd4e5c59558ed7e56a/0](/img/in-post/200603_ml_svm1/9b10d7fadba8dfb478203d1c8719f8d9.png)

当数据不能线性分割时，可投放到高维空间分割。

# 3基础知识

SVM目前被认为是最好的现成的分类器，SVM整个原理的推导过程也很是复杂啊，其中涉及到很多概念，如：凸优化问题、拉格朗日乘子法、对偶问题，slater条件、KKT条件还有复杂的SMO算法！

## 3.1 凸优化

### 3.1.1 凸集

在点集拓扑学与欧几里得空间中，凸集是一个点集，其中每两点之间的直线上的点都落在该点集中。请看下图：

![](/img/in-post/200603_ml_svm1/f710a5716d188c91ef5845e01adeaf0f.png)

### 3.1.2 凸函数

一个定义在向量空间的凸子集C(区间)上的实值函数f，如果在其定义域C上的任意两点x，y以及t∈[0,1]有： 

![这里写图片描述](/img/in-post/200603_ml_svm1/681b18271a97211835526c1214946289.png)

则该函数为凸函数！凸函数另一个判别方式是：如果一个凸函数是一个二阶可微函数，则它的二阶导数是非负的。上图：

![](/img/in-post/200603_ml_svm1/3f2782aee514a00687a64139f753aa11.png)

可以看出凸函数的二阶导非负；

### 3.1.3 凸优化

（百度百科）是指求取最小值的目标函数为凸函数的一类优化问题。其中，目标函数为凸函数且定义域为凸集的优化问题称为无约束凸优化问题。而目标函数和不等式约束函数均为凸函数，等式约束函数为仿射函数，并且定义域为凸集的优化问题为约束优化问题。

凸优化性质：

1、目的是求取目标函数的最小值；

2、目标函数和不等式约束函数都是凸函数，定义域是凸集；

3、若存在等式约束函数，则等式约束函数为仿射函数；

4、对于凸优化问题具有良好的性质，局部最优解便是全局最优解。

一个凸优化问题用公式描述为：

![è¿éåå¾çæè¿°](/img/in-post/200603_ml_svm1/4f661793cfecfcc41171346cf69dd165.png)

其目标函数f(x)

不等式约束条件g(x)便是凸函数

等式约束条件h(x)是仿射函数

仿射函数：即是deg(h(x))=1的函数，常数项为0的仿射函数称为线性函数。

其中符号 deg() 表示多项式h(x)的次数，即将函数看成多项式。

## 3.2 拉格朗日乘子法（考研必考题）

拉格朗日乘子法的作用：求函数f(x1,x2…)在g（x1,x2…）=0的约束条件下的极值。

1、定义新函数： 

![这里写图片描述](/img/in-post/200603_ml_svm1/ce0bd8bb22d5162919af03966c689fec.png)

2、利用偏导方式列出以下方程 

![这里写图片描述](/img/in-post/200603_ml_svm1/757fec558b250a71aafe141709cda647.png)

3、求解出x，y，σ的值带入F（x,y,σ）便是目标函数的极值。

## 3.3 对偶法

何为对偶？如下

maxminF(x)的对偶minxmaxF(x)；

即：最小值的最大值 对偶为：最大值的最小值；

作用：最大值中最小的一个总比最小值中最大的那一个要大，也就是对偶问题提供了原问题**最优值的一个下界**。

## 3.4 拉格朗日中的对偶应用

对于凸优化：

![](/img/in-post/200603_ml_svm1/5f15ef3d05be34ec7f48fee8eafc29f9.png)

使用拉格朗日乘子法针对上面的最优化问题有： 

![](/img/in-post/200603_ml_svm1/00a2ed38029c47943ba18da67a47a1c0.png)

需要明确：其中α≥0、β任意，均为拉格朗日乘子，i=1,2,…,p且j=1,2,…,q。

L(x,α,β)对x以及参数α和β进行求导，然后得出结果带入原始便可求出我们需要的最优解。存在问题：

1、这里参数α和β总共p+q个，如果全部求偏导工作量太大，不现实；   
2、并且大家有没有想过，这个问题可能根本就没有最优解这种情况存在。

对偶问题的性质：无论原命题的形式如何，对偶问题都是一个凸优化问题，凸优化问题的好处就是局部最优解就是全局最优解，且易求解，将问题转化为其对偶问题就简化了问题的求解思路。

自定义一个函数如下： 

![这里写图片描述](/img/in-post/200603_ml_svm1/ce2d362a8384b1e121e1f09ad2d2bbf8.png)

分析上面的自定义函数有： 

![](/img/in-post/200603_ml_svm1/85cb3cdeb273ec5e0673652660817f67.png)

（1）式，当目标函数的约束条件都满足时，就是求maxL，（2）式是只要目标函数的约束条件有一个不满足，则自定义的函数便等于无穷大！

也就是当满足约束时存在最大值，当不满足约束时为无穷大，那么问题就可归并为求最大值的最小值，（相对于原来变量x
无约束了），即可将最初的优化问题写成：

![è¿éåå¾çæè¿°](/img/in-post/200603_ml_svm1/a9fcb66e065aa6f1f8164c75c89d3e00.png)

其对偶便是：

![è¿éåå¾çæè¿°](/img/in-post/200603_ml_svm1/e094107d937462542f17dd2ebf024243.png)

令： 

![这里写图片描述](/img/in-post/200603_ml_svm1/33fbbd6a809f74102194f7989c0aecdb.png)

![这里写图片描述](/img/in-post/200603_ml_svm1/8af5abe0f1b3a1654a590f22dd2fb4df.png)

所以有： P\>=Q 

对偶问题提供了原问题最优值的一个下界，通过对偶问题求解原问题的最优解，所以只有当二者相等时即P=Q，才可能将原问题转化成对偶问题进行求解。当然，当满足一定条件的情况下，便有P=Q。而这个条件便是 slater条件和KTT条件。

slater条件：

slater条件官方正规定义：存在x，使得不等式约束g(x)\<=0严格成立。   
slater条件性质： slater条件是原问题P可以等价于对偶问题Q的一个充分条件，该条件确保了鞍点的存在。

## 3.5 KKT条件

**slater条件已经确保了鞍点的存在**，但是鞍点不一定就是最优解啊，所以KKT条件的作用便体现出来了。   
**KKT条件便是在鞍点中找出原函数最优解**的充分条件，当然对于我们前面举得那个例子，当原问题是凸优化问题时，则KKT条件便是鞍点便是最优解的充要条件。

## 3.5.1 KKT条件

![](/img/in-post/200603_ml_svm1/bdb554a77cb5c0eba5831df01264d610.png)

解释：

1：**最优点x**必须满足所有等式及不等式限制条件, 也就是说最优点必须是一个可行解,
这一点自然是毋庸置疑的；

2：在最优点x, ∇f必须是∇gi和∇hj的线性組合;

3：**拉格朗日乘子**不等式的一些限制，对于不等式的拉格朗日乘子限制条件有方向性,
所以每一个α都必须大于或等于零, 而等式限制条件没有方向性，只是β不等于0。

## 3.5.2 互补松弛解释

分成三种情况：

不等式约束等号成立，则拉格朗日乘子不为０；

不等式约束等号成立，则拉格朗日乘子为０；

不等式约束等号不成立，拉格朗日乘子为０；

不等式约束等号成立，则是支持向量。

不等式约束等号不成立，则是非支持向量。

延伸：

如果拉格朗日乘子＞０或＜０，则是一定支持向量

如果拉格朗日乘子＝０，则不一定支持向量

注意，对于等式约束的Lagrange乘子，并没有非负的要求！以后求其极值点，不必再引入松弛变量，直接使用KKT条件判断！

参考：

<https://blog.csdn.net/feilong_csdn/article/details/62427148>

<https://zhuanlan.zhihu.com/p/26514613>
