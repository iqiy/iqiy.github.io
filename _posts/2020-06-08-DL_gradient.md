---
layout: post
title: "DL学习笔记（一.一）"
subtitle: "梯度"
date: 2020-06-08 22:20:18
author: "QIY"
header-img: "img/DL.png"
header-mask: 0.3
catalog: true
tags:
    - Deep Learning
---


> Deep Learning 的学习需稳扎稳打 积累自己的小厂库

* TOC
{:toc}

# 1 导数到梯度

## 1.1 梯度

对于1元1阶导数：f’(x)

对于2元1阶导数：对于2元函数有2个自变量，常用x，y表示，即f(x,y)，导数也有x和y两个方向的分量，所以引入了偏导数，而偏导是沿一个方向即坐标轴方向的变化率，而**在多元函数中变化率可以是任意方向的**。此时就引入了梯度，所谓**梯度就是偏导数组成的列向量**。

换种表示方法，n元函数f(x1,x2,x3,,,,xn)，即当X=(x1,x2,x3,,,xn)T时，f(X)=
f(x1,x2,x3,,,,xn)；

梯度的表示符号用记为grad f（X）或▽f（X）=

![](/img/in-post/200608_Gradient/c71e026d79b955ecd2a14b78c4591afd.png)

所谓“**梯度的方向就是函数增大最快的方向**”，梯度的本身就是输入参数向量在函数方向上的偏导向量。

梯度方向的理解：

对于一元函数，自变量x在x轴方向活动；模型：平面

对于二元函数，自变量在x-y平面活动，方向任意；模型：三维立体

对于三元函数，自变量在x-y-z的三维立体空间活动，方向任意；模型

如二元函数中：

z=x2+y2图像：

![](/img/in-post/200608_Gradient/22d069edf826390aa883d784f56593fd.png)

可知梯度：gradient =[ 2\*x, 2\*y]

在点（2，2）的梯度向量可为[4,4]：

![](/img/in-post/200608_Gradient/758a924a6b37eb74fed632ced0ffc52b.png)

## 1.2 hession矩阵

对于多元2阶（hession矩阵）:

![](/img/in-post/200608_Gradient/e7c4335c636fe2f331babe2b9c6a1692.png)

hession矩阵为对称矩阵

## 1.3 Jacobian 矩阵

雅可比矩阵是一阶偏导数以一定方式排列成的矩阵, 其行列式称为雅可比行列式。

![](/img/in-post/200608_Gradient/3c912edb1e61e9032211878292ad8338.png)

此矩阵表示为: JF(x1,…,xn)JF(x1,…,xn) ,
或者∂(y1,…,ym)∂(x1,…,xn)∂(y1,…,ym)∂(x1,…,xn) .

这个矩阵的第i行是由梯度函数的转置yi(i=1,…,m)表示的.

hession和Jacobian的行列正好相反。

## 1.4 泰勒级数与极值（由标量到矢量）

标量：

![](/img/in-post/200608_Gradient/5a5e556a034000616af1054400bdce6c.png)

矢量：

![](/img/in-post/200608_Gradient/ff2cea0dc75d0cfa47e1f11de88a8a1c.png)

机器学习中所说的步长即：δ。

范数性质：1正定性/2齐次性/3三角不等性/4相容性。

\|\|a\|\| ：表示a的标量大小。

计算也不喜欢解方程，也喜欢迭代。

# 2 梯度下降与随机梯度下降

![](/img/in-post/200608_Gradient/192db38e7b8f84e883f6317abcd6e60a.png)

>   对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，**随机梯度下降法用于仅仅用一个样本决定梯度方向**，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。那么，有没有一个中庸的办法能够结合两种方法的优点呢？小**批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于m个样本，我们采用x个样子来迭代**，1\<x\<m。一般可以取x=10，当然根据样本的数据，可以调整这个x的值。对应的更新公式是：

![](/img/in-post/200608_Gradient/a18c46cd110347de3579363caa381b45.png)
>   \--end
